
import numpy as np
import json
import contextlib
import io
from aiida.orm import Dict, Code, KpointsData, load_node, JsonableData
from aiida.engine import WorkChain, run
from aiida.orm import Dict, List, Int, Float, Str
from aiida.engine import calcfunction

from .proposal_modes import propose_random_constraints, propose_random_so_n_constraints
from lordcapulet.utils import OccupationMatrixData, OccupationMatrixAiidaData, extract_occupations_from_calc, filter_atoms_by_species


def redirect_print_report(func, *args, **kwargs):
    buf = io.StringIO()
    with contextlib.redirect_stdout(buf):
        result = func(*args, **kwargs)
    output = buf.getvalue()
    return result, output

@calcfunction
def aiida_propose_occ_matrices_from_results(
    pk_list, N=8, debug=False, mode='random', *, reporter_type=None, tm_atoms=None, **kwargs):
    """
    AiiDA calcfunction that takes a list of PKs
    and returns a list of PKs of Dict nodes that are themselves stored
    and contain the occupation matrices. 

    This function wraps `propose_new_constraints` to create the Dict nodes.
    
    :param pk_list: List of PKs to load the occupation matrices from a AFMScanWorkChain or ConstrainedScanWorkChain.
    :param N: Int, number of dictionaries to return.
    :param debug: Bool, whether to print debug information.
    :param mode: Mode for selecting the dictionaries, e.g., 'random' or 'read'.
    :param kwargs: Additional keyword arguments for `propose_new_constraints`.

    :return: List of Dict nodes containing the occupation matrices.

    !!! WARNING PRINT STATEMENTS !!!

    This function uses print statements to log debug information.
    This is because it is a calcfunction wrapping AiiDA agnostic code.
    The print statements will be captured in the AiiDA report log.
    """

    if reporter_type == 'print':
        def reporter(msg):
            print(msg)
    else:
        reporter = None

    # load the nodes from the PKs and convert to unified format
    occ_matrices = []
    for pk in pk_list.get_list():
        node = load_node(pk)
        
        # Handle JsonableData nodes containing OccupationMatrixData (preferred)
        if hasattr(node, 'obj') and hasattr(node.obj, 'as_dict'):
            # This is a JsonableData node containing our OccupationMatrixData
            occupation_matrix_data = node.obj
            occ_matrices.append(occupation_matrix_data)
            print(f"Loaded occupation matrix from JsonableData node with PK {pk}")
        
        # Legacy support for saved matrix as Dict
        elif node.__class__.__name__ == "Dict":
            legacy_dict = node.get_dict()
            occupation_matrix_data = OccupationMatrixData.from_legacy_dict(legacy_dict)
            occ_matrices.append(occupation_matrix_data)
            # print a deprecated warning
            print(f"Warning: Loaded occupation matrix from Dict node with PK {pk}. This is deprecated, please use OccupationMatrixAiidaData.")
        
        # Handle calculation nodes directly (for backward compatibility)
        elif hasattr(node, 'process_type') and ('aiida.calculations:quantumespresso.pw' in node.process_type or 'aiida.calculations:lordcapulet.constrained_pw' in node.process_type):
            # try to get the output occupation matrix from the CalcJobNode using unified extractor
            try:
                occupation_matrix_data = extract_occupations_from_calc(node)
                occ_matrices.append(occupation_matrix_data)
                print(f"Warning: Extracted occupation matrix directly from CalcJobNode with PK {pk}. Consider using workchain outputs instead.")
            except Exception as e:
                raise ValueError(f"CalcJobNode with PK {pk}, error in parsing occupation_matrix: {e}")
        
        else:
            raise ValueError(f"Unsupported node type for PK {pk}: {type(node)}. Expected OccupationMatrixAiidaData, Dict, or CalcJobNode.")
        

    # now get the N dictionaries from the list


    # Convert AiiDA data types to native Python types for the internal function call
    # This is necessary because propose_new_constraints expects standard Python types,
    # but AiiDA calcfunctions receive AiiDA node types (Dict, List, Int, Float, Str)
    kwargs_internal = {}
    for key, value in kwargs.items():
        # Handle AiiDA Dict and List nodes by extracting their content
        if isinstance(value, (Dict, List)):
            # For List nodes: get_list() returns the Python list
            # For Dict nodes: get_dict() returns the Python dictionary
            kwargs_internal[key] = value.get_list() if isinstance(value, List) else value.get_dict()
        # Handle AiiDA numeric and string nodes by extracting their .value attribute
        elif isinstance(value, (Int, Float, Str)):
            kwargs_internal[key] = value.value
        # Raise error for any unsupported AiiDA node types
        else:
            raise ValueError(f"Unsupported AiiDA node type for key '{key}': {type(value)}. "
                           f"Only Dict, List, Int, Float, and Str nodes are supported.")
    # check if this ran in the debug mode
    if debug and reporter is not None:
        reporter(f"Loaded {len(occ_matrices)} occupation matrices from nodes with PKs: {pk_list.get_list()}")
        reporter(f"Using proposal mode: {mode.value} with N = {N.value} samples per generation")



    # Filter atoms by species if tm_atoms is provided
    if tm_atoms is not None:
        tm_atoms_list = tm_atoms.get_list() if hasattr(tm_atoms, 'get_list') else tm_atoms
        filtered_matrices = []
        for occ_matrix_data in occ_matrices:
            filtered_data = filter_atoms_by_species(occ_matrix_data, tm_atoms_list)
            filtered_matrices.append(filtered_data)
        occ_matrices = filtered_matrices

    if debug.value:
        print(f"Loaded {len(occ_matrices)} OccupationMatrixData objects")
        for i, occ_data in enumerate(occ_matrices):
            print(f"  Matrix {i+1}: {len(occ_data)} atoms, species: {occ_data.get_atom_species()}")

    # Generate proposals using OccupationMatrixData directly (no conversion to legacy format)
    proposals, to_report = redirect_print_report(
                                    propose_new_constraints,
                                    occ_matr_list=occ_matrices,
                                    N=N.value,
                                    debug=debug.value,
                                    mode=mode.value,
                                    **kwargs_internal
                                    )

    # this does not work as it should, needs refactoring

    # if self is not None:
    #     self.report(to_report)

    # Store proposals as JsonableData nodes
    # Proposals are already OccupationMatrixData objects with metadata preserved
    dict_nodes = []
    for proposal in proposals:
        # Store as JsonableData
        json_node = JsonableData(proposal)
        json_node.store()
        dict_nodes.append(json_node)

    # return a list of the PKs of the Dict nodes
    return List(list=[node.pk for node in dict_nodes])


def propose_new_constraints(occ_matr_list, N, mode='random', debug=True, **kwargs):
    """
    Generate N new occupation matrix proposals from existing data.
    
    !!IMPORTANT!! THIS FUNCTION SHOULD NOT GET ANY AIIDA TYPES AS INPUT
    
    :param occ_matr_list: List of OccupationMatrixData objects to use as reference
    :param N: Number of proposals to generate
    :param mode: Proposal generation mode ('random', 'random_so_n', or 'read')
    :param debug: Whether to print debug information
    :param kwargs: Additional mode-specific parameters
    :return: List of N OccupationMatrixData objects (proposals)
    """
    if N < 1:
        raise ValueError("N must be greater than or equal to 1")
    
    # Get dimensions from first occupation matrix
    first_occ_data = occ_matr_list[0]
    natoms = len(first_occ_data)
    first_atom_label = first_occ_data.get_atom_labels()[0]
    norbitals = len(first_occ_data.get_occupation_matrix(first_atom_label, 'up'))
    nspin = 2  # up and down spin

    if debug:
        print(f"Number of atoms: {natoms}")
        print(f"Number of spins: {nspin}")
        print(f"Number of orbitals: {norbitals}")
        print(f"Atom labels: {first_occ_data.get_atom_labels()}")
        print(f"Atom species: {first_occ_data.get_atom_species()}")

    # implement case switch for mode
    match mode:

        case 'random':
            proposals = propose_random_constraints(occ_matr_list, natoms,  N, debug=debug, **kwargs)

        case 'random_so_n':
            proposals = propose_random_so_n_constraints(occ_matr_list, natoms, N, debug=debug, **kwargs)

        case 'read':
            # check if there is readfile in kwargs
            if 'readfile' not in kwargs:
                raise ValueError("readfile must be provided in kwargs for read mode")
            readfile = kwargs['readfile']
            # read the json file
            with open(readfile, 'r') as f:
                loaded_data = json.load(f)
            # assert that the loaded list is longer than N
            if len(loaded_data) < N:
                raise ValueError(f"Loaded data has only {len(loaded_data)} dictionaries, but N is {N}")

            # now loaded_data[iteration]['occupation_numbers'][iatom][ispin] is a norbital x norbital matrix


            #create now a list of dictionaries
            target_matrix_np = np.zeros((natoms, nspin, norbitals, norbitals))

            proposals = []
            for iteration in range(0, N):
                proposal = {}
                for iatom in range(natoms):
                    for ispin in range(nspin):
                        target_matrix_np[iatom, ispin] = \
                            np.array(loaded_data[iteration]['occupation_numbers'][iatom][ispin])
                proposal['matrix'] = target_matrix_np.tolist()
                proposals.append(proposal)
            if debug:
                print(f"Reading {N} dictionaries from file")

        
        
    
    return proposals